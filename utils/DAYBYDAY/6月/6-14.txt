atom
    关闭welcome
    报错"Cannot load the system dictionary for zh-CN"    禁用 spell(packages)
    关闭白线 File > Stylesheet 粘贴CSS代码

scrapy Scrapy Engine 爬虫引擎
    scrapy crawl 来启动Scrapy
    分布式爬虫
        有很多spider，那分布负载最简单的办法就是启动多个Scrapyd，并分配到不同机器上
        多个机器上运行一个单独的spider，那您可以将要爬取的url进行分块，并发送给spider
    反爬虫
        user-agent， 禁用cookie； 下载延迟 2； 通过搜索引擎访问；IP池；下载器高度分布式

    Broad Crawls  通用爬虫
        全局并发数 并发是指同时处理的request的数量
        CONCURRENT_REQUESTS = 100

        LOG_LEVEL = 'INFO' log级别
        COOKIES_ENABLED = False 禁用cookie
        RETRY_ENABLED = False 禁止重试
        DOWNLOAD_TIMEOUT = 15 减小下载超时
        REDIRECT_ENABLED = False 关闭重定向
        AJAXCRAWL_ENABLED = True 启用ajax爬取

    工具 Firefox  Firebug

    调试内存溢出
        telnet终端并通过 prefs() 功能
        scrapy.http.Request
        scrapy.http.Response
        scrapy.item.Item
        scrapy.selector.Selector
        scrapy.spider.Spider

    下载及处理文件和图片
        Files Pipeline或者 Images Pipeline

    Deploying Spiders
    自动限速(AutoThrottle)扩展
    性能测试

    Jobs: 暂停，恢复爬虫
        一个把调度请求保存在磁盘的调度器
        一个把访问请求保存在磁盘的副本过滤器[duplicates filter]
        一个能持续保持爬虫状态(键/值对)的扩展

            Job 路径 scrapy crawl somespider -s JOBDIR=crawls/somespider-1 恢复也是这个命令
             self.state['items_count'] = self.state.get('items_count', 0) + 1 spider状态

    架构概览
        下载器中间件(Downloader middlewares)  处理Downloader传递给引擎的response
        Spider中间件(Spider middlewares  处理spider的输入(response)和输出(items及requests)

    下载器中间件
        激活
        DOWNLOADER_MIDDLEWARES = {
        'myproject.middlewares.CustomDownloaderMiddleware': 543,
}
        中间件的有序列表
        关闭user-agent中间件:
        DOWNLOADER_MIDDLEWARES = {
        'myproject.middlewares.CustomDownloaderMiddleware': 543,
        'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware': None,
}
    process_request(request, spider)
        request通过下载中间件时，该方法被调用   返回 None 、返回一个 Response 对象、返回一个 Request 对象或raise IgnoreRequest
        如果其返回 None ，Scrapy将继续处理该request，执行其他的中间件的相应方法，直到合适的下载器处理函数(download handler)被调用    如果其返回 Response 对象   其将返回该response
        如果其返回 None ，Scrapy将继续处理该request，执行其他的中间件的相应方法，直到合适的下载器处理函数(download handler)被调用    如果其返回 Response 对象   其将返回该response

    Spider中间件
        SPIDER_MIDDLEWARES 设置会与Scrapy定义的 SPIDER_MIDDLEWARES_BASE 设置合并(但不是覆盖)， 而后根据顺序(order)进行排序，最后得到启用中间件的有序列表: 第一个中间件是最靠近引擎的，最后一个中间件是最靠近spider的。

    核心API
        crapy API的主要入口是 Crawler 的实例对象， 通过类方法 from_crawler 将它传递给扩展(extensions)。 该对象提供对所有Scrapy核心组件的访问， 也是扩展访问Scrapy核心组件和挂载功能到Scrapy的唯一途径。

    Item Exporters
        持久化或导出它们
